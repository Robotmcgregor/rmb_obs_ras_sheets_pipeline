{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the static plots again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas to read your zonal stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter your inputs here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the fractional cover zonal stats csv\n",
    "output_zonal_stats_ = r\"Z:\\Scratch\\Zonal_Stats_Pipeline\\rmb_fractional_cover_zonal_stats\\outputs\\ste10_20211112_0934\\zonal_stats\\EKD_Elkedra_102075_zonal_stats.csv\"\n",
    "output_zonal_stats = pd.read_csv(output_zonal_stats_, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the rainfall zonal stats csv\n",
    "output_rainfall_ = r\"Z:\\Scratch\\Zonal_Stats_Pipeline\\rmb_fractional_cover_zonal_stats\\outputs\\ste10_20211112_0934\\rainfall\\EKD_Elkedra_102075_rainfall_zonal_stats.csv\"\n",
    "output_rainfall = pd.read_csv(output_rainfall_, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the NT_Star_Transect shapefile - on remote desktop keep this path as is\n",
    "previous_visits = r\"E:\\DENR\\code\\rangeland_monitoring\\rmb_fractional_cover_zonal_stats_pipeline_tif\\assets\\shapefiles\\NT_StarTransect_20200713.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landsat tile in the format \"123_123\"\n",
    "complete_tile = \"101_075\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the output directory\n",
    "plot_dir = r\"Z:\\Scratch\\Zonal_Stats_Pipeline\\rmb_fractional_cover_zonal_stats\\outputs\\test\\plot_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep this at 3\n",
    "rolling_mean = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the date that you want the plot to stop.\n",
    "finish_date = '2021-09-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the next two code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your static plots will be output into the directory you listed for “Plot_output”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2020 Rob McGregor, script modified from zzzz Grant Staben 2019\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the 'Software'), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "\n",
    "THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# import modules.\n",
    "from __future__ import print_function, division\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mpl.rcParams['figure.figsize'] = (30, 8.0)\n",
    "\n",
    "\n",
    "def previous_visits_fn(previous_visits):\n",
    "    \"\"\" Read in and clean the integrated site shapefile for previous site visit information.\n",
    "\n",
    "    @param previous_visits: latest shapefile containing previous visits to the site.\n",
    "    @return integrated: open geo-dataframe. \"\"\"\n",
    "\n",
    "    #previous_visits = r\"E:\\DENR\\code\\rangeland_monitoring\\rmb_zonal_plots_ploting_pipeline\\assets\\shapefiles\\NT_StarTransect_20200713.shp\"\n",
    "    # Import the integrated site shapefile for previous visit dates to the site.\n",
    "    integrated = gpd.read_file(previous_visits)\n",
    "    # convert site name to capital letters\n",
    "    integrated['siteTitle'] = integrated.site.str.upper()\n",
    "    # add a datTime feature from the obs_time variables.\n",
    "    integrated['dateTime'] = integrated.obs_time.apply(pd.to_datetime)\n",
    "\n",
    "    return integrated\n",
    "\n",
    "\n",
    "def import_rainfall_data_fn(output_rainfall):\n",
    "    \"\"\" Import the output_rainfall pandas data frame to add a date feature from the image variable and sort based on\n",
    "        image date.\n",
    "\n",
    "        @param output_rainfall: pandas data frame object containing all rainfall zonal stat records within the rainfall\n",
    "        directory.\n",
    "        @return output_rainfall: pandas data frame object that has been processed - additional features and sorted based\n",
    "        on date.\n",
    "        \"\"\"\n",
    "\n",
    "    # create the date time field and sort the values\n",
    "    output_rainfall['year'] = output_rainfall['im_date'].map(lambda x: str(x)[:4])\n",
    "    output_rainfall['month'] = output_rainfall['im_date'].map(lambda x: str(x)[4:6])\n",
    "    output_rainfall['Date'] = output_rainfall['year'] + '/' + output_rainfall['month'] + '/' + '15'\n",
    "    output_rainfall.sort_values(['Date'])\n",
    "\n",
    "    # convert site_date feature from object to datetime\n",
    "    output_rainfall['site_date'] = pd.to_datetime(output_rainfall['site_date'])\n",
    "    return output_rainfall\n",
    "\n",
    "\n",
    "def import_zonal_stats_fn(output_zonal_stats):\n",
    "    \"\"\" Import the output_zonal_stats pandas data frame to add a date feature from the image variable, remove\n",
    "    observations with less than three pixel counts and sort based on image date.\n",
    "\n",
    "    @param output_zonal_stats: pandas data frame object containing all rainfall zonal stat records within the\n",
    "    zonal_stats directory.\n",
    "    @return output_zonal_stats: pandas data frame object that has been processed - additional features and sorted\n",
    "    based on date.\n",
    "    \"\"\"\n",
    "\n",
    "    output_zonal_stats['site_date'] = pd.to_datetime(output_zonal_stats['site_date'])\n",
    "    # remove all data points which do not have at least 3 valid pixels to produce the average bare ground for a site\n",
    "    output_zonal_stats = output_zonal_stats.loc[(output_zonal_stats['b1_count'] > 3)]\n",
    "    # create the date time field and sort the values\n",
    "    output_zonal_stats['dateTime'] = output_zonal_stats['year'].apply(str) + \"/\" + output_zonal_stats['month'].apply(\n",
    "        str) + \"/\" + output_zonal_stats['day'].apply(str)\n",
    "    output_zonal_stats['dateTime'] = output_zonal_stats.dateTime.apply(pd.to_datetime)\n",
    "    # sort values by dateTime.\n",
    "    output_zonal_stats.sort_values(['dateTime'])\n",
    "\n",
    "    return output_zonal_stats\n",
    "\n",
    "\n",
    "def rainfall_data_amend_fn(output_rainfall, i):\n",
    "    \"\"\" Filter rainfall data by site convert the rainfall mean to mm, and extract the required series and variables.\n",
    "\n",
    "        @param output_rainfall: pandas data frame object that has been processed subject to the import_rainfall_data_fn\n",
    "            function.\n",
    "        @param i: for loop variable (site name) from the unique name list form the output_rainfall data frame.\n",
    "        @return rain: pandas series with the rainfall mean converted to mm.\n",
    "        @return date: pandas series object sorted by date.\n",
    "        @return site_label: string objet assigned the variable i.\n",
    "        \"\"\"\n",
    "\n",
    "    # select the site to plot\n",
    "    site_s = output_rainfall.loc[(output_rainfall.comp_site == i)]\n",
    "\n",
    "    site_label = str(i)\n",
    "\n",
    "    property_name = output_rainfall.prop_name.unique()\n",
    "    prop = property_name[0]\n",
    "\n",
    "    site_date = output_rainfall.site_date.unique()\n",
    "    s_date = site_date[0]\n",
    "\n",
    "    # read in the rainfall stats and covert them to total mm\n",
    "    site_sort = site_s.sort_values(['Date'])\n",
    "    date = pd.Series(site_sort['Date']).apply(pd.to_datetime)\n",
    "    rain = site_sort['mean'] / 10\n",
    "\n",
    "    return rain, date, site_label\n",
    "\n",
    "\n",
    "def b1_fn(output_zonal_stats, i, rolling_mean):\n",
    "    \"\"\" Calculate rolling average for band 1 and create to series objet with interpolated values where required.\n",
    "\n",
    "    @param output_zonal_stats: pandas data frame object that has been processed subject to the import_zonal_stats_fn\n",
    "    function.\n",
    "    @param i: string objet containing the site name - iteration of the for loop.\n",
    "    @param rolling_mean: integer object containing the rolling mean variable.\n",
    "    @return values_bg: pandas series with null values interpolated.\n",
    "    @return date_fit_bg: pandas series with the dateTime feature converted to pandas datetime variables from\n",
    "    strings(objects).\n",
    "    \"\"\"\n",
    "\n",
    "    # use all predicted bare fractional cover values to produce the fitted line\n",
    "    lsat_bg = output_zonal_stats.loc[(output_zonal_stats['comp_site'] == i)]\n",
    "    date_bg = lsat_bg.sort_values(['dateTime'])\n",
    "    # ('date_bg: ', type(date_bg))\n",
    "    date_fit_bg = pd.Series(date_bg['dateTime']).apply(pd.to_datetime)\n",
    "    mean_bg = date_bg['b1_mean']\n",
    "\n",
    "    # currently set to calculate the rolling mean for five points\n",
    "    mean_b_gfl = mean_bg.rolling(rolling_mean, center=True).mean()\n",
    "\n",
    "    # interpolate the missing values to enable it to be plotted\n",
    "    interp_bg = mean_b_gfl.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    values_bg = interp_bg.values\n",
    "\n",
    "    return values_bg, date_fit_bg\n",
    "\n",
    "\n",
    "def b2_fn(output_zonal_stats, i, rolling_mean):\n",
    "    \"\"\" Calculate rolling average for band 2 and create to series objet with interpolated values where required.\n",
    "\n",
    "    @param output_zonal_stats: pandas data frame object that has been processed subject to the import_zonal_stats_fn\n",
    "    function.\n",
    "    @param i: string objet containing the site name - iteration of the for loop.\n",
    "    @param rolling_mean: integer object containing the rolling mean variable.\n",
    "    @return values_bg: pandas series with null values interpolated.\n",
    "    @return date_fit_bg: pandas series with the dateTime feature converted to pandas datetime variables from\n",
    "    strings(objects).\"\"\"\n",
    "\n",
    "    # use all predicted green fraction cover values to produce the fitted line\n",
    "    lsat_pv = output_zonal_stats.loc[(output_zonal_stats['comp_site'] == i)]\n",
    "    date_pv = lsat_pv.sort_values(['dateTime'])\n",
    "    date_fit_pv = pd.Series(date_pv['dateTime']).apply(pd.to_datetime)\n",
    "    mean_pv = date_pv['b2_mean']\n",
    "\n",
    "    # currently set to calculate the rolling mean for four points\n",
    "    mean_p_vfl = mean_pv.rolling(rolling_mean, center=True).mean()  # changed from 5\n",
    "\n",
    "    # interpolate the missing values to enable it to be plotted\n",
    "    interp_pv = mean_p_vfl.interpolate(method='linear', limit_direction='both')\n",
    "    vals_pv = interp_pv.values\n",
    "\n",
    "    return vals_pv, date_fit_pv\n",
    "\n",
    "\n",
    "def b3_fn(output_zonal_stats, i, rolling_mean):\n",
    "    \"\"\" Calculate rolling average for band 3 and create to series objet with interpolated values where required.\n",
    "\n",
    "    @param output_zonal_stats: pandas data frame object that has been processed subject to the import_zonal_stats_fn\n",
    "    function.\n",
    "    @param i: string objet containing the site name - iteration of the for loop.\n",
    "    @param rolling_mean: integer object containing the rolling mean variable.\n",
    "    @return values_bg: pandas series with null values interpolated.\n",
    "    @return date_fit_bg: pandas series with the dateTime feature converted to pandas datetime variables from\n",
    "    strings(objects).\n",
    "    \"\"\"\n",
    "\n",
    "    # use all predicted NPV fractional cover values to produce the fitted line\n",
    "    lsat_npv = output_zonal_stats[(output_zonal_stats['comp_site'] == i)]\n",
    "    date_npv = lsat_npv.sort_values(['dateTime'])\n",
    "    date_fit_npv = pd.Series(date_npv['dateTime']).apply(pd.to_datetime)\n",
    "    mean_npv = date_npv['b3_mean']\n",
    "\n",
    "    # Calculate the rolling mean for four points\n",
    "    mean_np_vfl = mean_npv.rolling(rolling_mean, center=True).mean()  # changed from 5\n",
    "\n",
    "    # interpolate the missing values to enable it to be plotted\n",
    "    interp_npv = mean_np_vfl.interpolate(method='linear', limit_direction='both')\n",
    "    vals_npv = interp_npv.values\n",
    "\n",
    "    return vals_npv, lsat_npv, date_fit_npv\n",
    "\n",
    "\n",
    "def plot_bare_ground_fn(lsat_npv, values, date, rain, integrated, complete_tile, site_label, start_date, finish_date,\n",
    "                        date_fit_bg, s_date, i, plot_outputs, prop_name):\n",
    "    \"\"\" Create and export a static time series plot with rainfall and bare ground data only.\n",
    "\n",
    "    @param lsat_npv:\n",
    "    @param values:\n",
    "    @param date:\n",
    "    @param rain:\n",
    "    @param integrated:\n",
    "    @param complete_tile:\n",
    "    @param site_label:\n",
    "    @param start_date:\n",
    "    @param finish_date:\n",
    "    @param date_fit_bg:\n",
    "    @param s_date:\n",
    "    @param i:\n",
    "    @param plot_outputs:\n",
    "    @param prop_name:\n",
    "    @return fig:\n",
    "    \"\"\"\n",
    "    print('='*50)\n",
    "    print('plot_bare_g complete tile: ', complete_tile)\n",
    "\n",
    "    # --------------------------------------------- BARE GROUND PLOT ---------------------------------------------------\n",
    "\n",
    "    # get the site name for the plot title\n",
    "    s_name = str(lsat_npv.site.unique())\n",
    "    site_name = s_name.strip(\"['']\")\n",
    "\n",
    "    # set up the format for the plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    # set up the x axis limits using pandas\n",
    "    ax.set_xlim(pd.Timestamp(start_date), pd.Timestamp(finish_date))\n",
    "    # ax.set_xlim(start_date, finish_date)\n",
    "\n",
    "    barax = ax.twinx()\n",
    "    barax.bar(date, rain, width=20, color='#00539C', label='Rainfall')  # , alpha=0.15\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # add bare ground data to the plot\n",
    "    ax.plot(date_fit_bg, values, linestyle='-', linewidth=2, color='#E13B18', label='Bare ground')\n",
    "\n",
    "    # add av line representing previous visits to the site.\n",
    "    # plt.axvline(x = s_date, color ='r') #, linestyle = '--', linewidth = 1)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------------\n",
    "    years = mdates.YearLocator(1)  # 2 plots up every second year\n",
    "    months = mdates.MonthLocator()  # every month\n",
    "    yearsFmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "    # format the ticks\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(yearsFmt)\n",
    "    ax.xaxis.set_minor_locator(months)  # Tick every year on Jan 1st\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # add legend in the fixed position and use numpoints=1 to only show one point\n",
    "    # otherwise it will show two points which is annoying\n",
    "    # ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.legend(loc=2, numpoints=1, prop={'size': 20})\n",
    "    ax.set_title(\"Time Trace - site \" + site_name, fontsize=25)\n",
    "    ax.set_xlabel('Year', fontsize=25)\n",
    "\n",
    "    # ----------------------------------------- Select x y axis label --------------------------------------------------\n",
    "    ax.set_ylabel('Bare Ground (%)', fontsize=20)\n",
    "    barax.set_ylabel('Monthly Rainfall (mm)', fontsize=20)\n",
    "    barax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    barax.legend(loc=1, numpoints=1, prop={'size': 20})\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    # Add the current years inspection date.\n",
    "\n",
    "    plt.axvline(x=pd.Timestamp(s_date), color='dimgrey', linestyle='--')\n",
    "\n",
    "    # Add previous dates from the star transect shapefile.\n",
    "    integrated_site = integrated.loc[integrated['siteTitle'] == i]\n",
    "    list_date = integrated_site.dateTime.unique().tolist()\n",
    "\n",
    "    list_length = len(list_date)\n",
    "\n",
    "    if list_length >= 1:\n",
    "\n",
    "        for i in list_date:\n",
    "            plt.axvline(x=pd.Timestamp(i), color='dimgrey', linestyle='--')\n",
    "\n",
    "    output_name = (plot_outputs + '\\\\BG_plot_' + str(i) + '_' + str(complete_tile) + '_' + str(start_date).replace('-', '') + '_' + str(finish_date).replace('-', '') + '.png')\n",
    "    fig.savefig(output_name, dpi=150, bbox_inches='tight')  # bbox_inches removes the white space\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_all_bands_fn(lsat_npv, date, rain, values_bg, values_pv, values_npv, integrated, complete_tile, site_label,\n",
    "                      start_date, finish_date, date_fit_bg, date_fit_pv, date_fit_npv, s_date, i, plot_outputs, prop_name):\n",
    "    \"\"\" Create and export a static time series plot with rainfall and bare ground, npv and pv data.\n",
    "\n",
    "    @param lsat_npv:\n",
    "    @param date:\n",
    "    @param rain:\n",
    "    @param values_bg:\n",
    "    @param values_pv:\n",
    "    @param values_npv:\n",
    "    @param integrated:\n",
    "    @param complete_tile:\n",
    "    @param site_label:\n",
    "    @param start_date:\n",
    "    @param finish_date:\n",
    "    @param date_fit_bg:\n",
    "    @param date_fit_pv:\n",
    "    @param date_fit_npv:\n",
    "    @param s_date:\n",
    "    @param i:\n",
    "    @param plot_outputs:\n",
    "    @param prop_name:\n",
    "    @return fig:\n",
    "    \"\"\"\n",
    "    s_name = str(lsat_npv.site.unique())\n",
    "    site_name = s_name.strip(\"['']\")\n",
    "\n",
    "    # set up the format for the plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    # set up the x axis limits using pandas\n",
    "    ax.set_xlim(pd.Timestamp(start_date), pd.Timestamp(finish_date))\n",
    "    # ax.set_xlim(start_date, finish_date)\n",
    "\n",
    "    bar_ax = ax.twinx()\n",
    "    bar_ax.bar(date, rain, width=20, color='#00539C', label='Rainfall', alpha=0.15)  # , alpha=0.15\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # plot all three data fields (bare ground, npv and pv)\n",
    "    ax.plot(date_fit_bg, values_bg, linestyle='-', linewidth=2, color='#E13B18', label='Bare ground')\n",
    "    ax.plot(date_fit_pv, values_pv, linestyle='-', linewidth=2, color='green', label='PV')\n",
    "    ax.plot(date_fit_npv, values_npv, linestyle='-', linewidth=2, color='#1873E1', label='NPV')\n",
    "\n",
    "    # plt.axvline(x = s_date, color ='r') #, linestyle = '--', linewidth = 1)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------------\n",
    "    years = mdates.YearLocator(1)  # 2 plots up every second year\n",
    "    months = mdates.MonthLocator()  # every month\n",
    "    years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "    # format the ticks\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "    ax.xaxis.set_minor_locator(months)  # Tick every year on Jan 1st\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # add legend in the fixed position and use numpoints=1 to only show one point otherwise\n",
    "    # it will show two points which is annoying\n",
    "    # ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.legend(loc=2, numpoints=1, prop={'size': 20})\n",
    "    ax.set_title(\"Time Trace - site \" + site_name, fontsize=25)\n",
    "    ax.set_xlabel('Year', fontsize=25)\n",
    "\n",
    "    # ------------------------------------------- Select a y axis label ------------------------------------------------\n",
    "\n",
    "    ax.set_ylabel('Bare Ground (%)', fontsize=20)\n",
    "    ax.set_ylabel('Photosynthetic Vegetation (%)', fontsize=20)\n",
    "    ax.set_ylabel('Non-photosynthetic Vegetation (%)', fontsize=20)\n",
    "    ax.set_ylabel('Fractional Cover (%)', fontsize=20)\n",
    "\n",
    "    bar_ax.set_ylabel('Monthly Rainfall (mm)', fontsize=20)\n",
    "    bar_ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    bar_ax.legend(loc=1, numpoints=1, prop={'size': 20})\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plt.axvline(x=pd.Timestamp(s_date), color='dimgrey', linestyle='--')\n",
    "\n",
    "    # Add previous dates from the star transect shapefile.\n",
    "    integrated_site = integrated.loc[integrated['siteTitle'] == i]\n",
    "    list_date = integrated_site.dateTime.unique().tolist()\n",
    "\n",
    "    list_length = len(list_date)\n",
    "\n",
    "    if list_length >= 1:\n",
    "\n",
    "        for i in list_date:\n",
    "            plt.axvline(x=pd.Timestamp(i), color='dimgrey', linestyle='--')\n",
    "\n",
    "    output_name = (plot_outputs + '\\\\All_B_interp_' + str(i) + '_' + str(complete_tile) + '_' + str(start_date).replace('-', '') + '_' + str(finish_date).replace('-', '') + '.png')\n",
    "    fig.savefig(output_name, dpi=150, bbox_inches='tight')  # bbox_inches removes the white space\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date:  1988-05-01\n",
      "finish_date:  2021-09-30\n",
      "complete_tile:  101_075\n",
      "==================================================\n",
      "plot_bare_g complete tile:  101_075\n",
      "==================================================\n",
      "plot_bare_g complete tile:  101_075\n",
      "==================================================\n",
      "plot_bare_g complete tile:  101_075\n",
      "==================================================\n",
      "plot_bare_g complete tile:  101_075\n",
      "==================================================\n",
      "plot_bare_g complete tile:  101_075\n",
      "==================================================\n",
      "plot_bare_g complete tile:  101_075\n",
      "==================================================\n",
      "plot_bare_g complete tile:  101_075\n",
      "Plotting is complete........\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Produce static time series plot from the matplotlib module from fractional cover and rainfall zonal stat\n",
    "information.\n",
    "    :param plot_dir: string object containing the plot directory path.\n",
    "    :param rolling_mean: integer object controlling the rolling mean.\n",
    "    :param finish_date: either the last date or the rainfall data or the date override (command argument) to end the\n",
    "        plots.\n",
    "    :param output_zonal_stats: pandas data frame object containing all fractional cover zonal stats records identified\n",
    "        in the zonal_stats directory.\n",
    "    :param output_rainfall: pandas data frame object containing all rainfall zonal stats records identified\n",
    "        in the zonal_stats directory.\n",
    "    :param complete_tile: string object containing the landsat tile name.\n",
    "    :param previous_visits: string object containing the path to the latest integrated site shapefile with previous\n",
    "        visits data.\n",
    "    :return fig: static time series plot. \"\"\"\n",
    "\n",
    "# print('step2_2_bare_ground_plots.py INITIATED.')\n",
    "#output_zonal_stats_ = r\"Z:\\Scratch\\Zonal_Stats_Pipeline\\rmb_fractional_cover_zonal_stats\\outputs\\ste10_20211112_1315\\zonal_stats\\ATW_Annitowa_101075_zonal_stats.csv\"\n",
    "#output_zonal_stats = output_zonal_stats\n",
    "#output_rainfall_ = r\"Z:\\Scratch\\Zonal_Stats_Pipeline\\rmb_fractional_cover_zonal_stats\\outputs\\ste10_20211112_1315\\rainfall\\ATW_Annitowa_101075_rainfall_zonal_stats.csv\"\n",
    "#output_rainfall = output_rainfall\n",
    "#complete_tile = \"101_075\"\n",
    "#previous_visits\n",
    "#plot_dir = r\"Z:\\Scratch\\Zonal_Stats_Pipeline\\rmb_fractional_cover_zonal_stats\\outputs\\test\\plot_outputs\"\n",
    "#rolling_mean = 3\n",
    "#finish_date = '1988-05-01'\n",
    "# define the start and finish dates from the plots\n",
    "#output_zonal_stats = pd.read_csv(output_zonal_stats_)\n",
    "start_date = '1988-05-01'\n",
    "print('start_date: ', start_date)\n",
    "print('finish_date: ', finish_date)\n",
    "print('complete_tile: ', complete_tile)\n",
    "\n",
    "# call previous visits function.\n",
    "integrated = previous_visits_fn(previous_visits)\n",
    "\n",
    "output_rainfall = import_rainfall_data_fn(output_rainfall)\n",
    "\n",
    "output_zonal_stats = import_zonal_stats_fn(output_zonal_stats)\n",
    "\n",
    "for i in output_rainfall.comp_site.unique():\n",
    "    # print('working on site: ', i)\n",
    "    prop_name = output_rainfall.prop_name.iloc[0].title().replace(' ', '_')\n",
    "    #rain, date, site_label = rainfall_data_amend_fn(output_rainfall, i)\n",
    "\n",
    "    # select the site to plot\n",
    "    site_s = output_rainfall.loc[(output_rainfall.comp_site == i)]\n",
    "\n",
    "    site_label = str(i)\n",
    "\n",
    "    #property_name = output_rainfall.prop_name.unique()\n",
    "    #prop = property_name[0]\n",
    "\n",
    "    #site_date = output_rainfall.site_date.unique()\n",
    "    #s_date = site_date[0]\n",
    "\n",
    "    site_date = output_rainfall.site_date.unique()\n",
    "    s_date = site_date[0]\n",
    "\n",
    "    # read in the rainfall stats and covert them to total mm\n",
    "    site_sort = site_s.sort_values(['Date'])\n",
    "    date = pd.Series(site_sort['Date']).apply(pd.to_datetime)\n",
    "    rain = site_sort['mean'] / 10\n",
    "\n",
    "    values_bg, date_fit_bg = b1_fn(output_zonal_stats, i, rolling_mean)\n",
    "    values_pv, date_fit_pv = b2_fn(output_zonal_stats, i, rolling_mean)\n",
    "    values_npv, lsat_npv, date_fit_npv = b3_fn(output_zonal_stats, i, rolling_mean)\n",
    "\n",
    "    fig = plot_bare_ground_fn(lsat_npv, values_bg, date, rain, integrated, complete_tile, site_label, start_date,\n",
    "                              finish_date,\n",
    "                              date_fit_bg, s_date, i, plot_dir, prop_name)\n",
    "\n",
    "    fig = plot_all_bands_fn(lsat_npv, date, rain, values_bg, values_pv, values_npv, integrated, complete_tile,\n",
    "                            site_label, start_date, finish_date, date_fit_bg, date_fit_pv, date_fit_npv, s_date, i,\n",
    "                            plot_dir, prop_name)\n",
    "\n",
    "print('Plotting is complete........')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
